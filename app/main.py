from fastapi import FastAPI
from contextlib import asynccontextmanager
from fastapi.middleware.cors import CORSMiddleware

from app.api.chat_direct import chat_direct_router
from app.api.upload import upload_router
from app.api.delete_vector import delete_router
from app.core.config import settings

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Validate settings at startup
    if not all([
        settings.OPENAI_API_KEY,
        settings.PINECONE_API_KEY,
        settings.PINECONE_ENV,
        settings.PINECONE_INDEX_NAME
    ]):
        raise ValueError("Missing required environment variables")
    yield
    # Optional: Cleanup tasks

app = FastAPI(
    title=settings.PROJECT_NAME,
    version=settings.VERSION,
    description=settings.DESCRIPTION,
    openapi_url=f"{settings.API_V1_STR}/openapi.json",
    lifespan=lifespan
)

# Set up CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Register API routers
app.include_router(chat_direct_router)
app.include_router(upload_router)  # ✅ Register upload router
app.include_router(delete_router)  # ✅ Register upload router


@app.get("/health")
async def health():
    return {"status": "healthy"}

@app.get("/")
async def read_root():
    return {
        "message": "THIS IS THE BASE URL FOR THE CHAT BOT",
        "endpoints": {
            "/health": {
                "method": "GET",
                "description": "Check if the server is healthy.",
                "response": {"status": "healthy"}
            },
            "/testing": {
                "method": "POST",
                "description": "Test endpoint that requires a POST request with a message in the body. The server will respond directly from OpenAI's model.",
                "request_body": {
                    "message": "string (Your message to OpenAI model)"
                },
                "response": {
                    "response": "string (Direct response from OpenAI model)"
                }
            },
            "/chat": {
                "method": "POST",
                "description": "Chat endpoint using Pinecone and RAG (Retrieval-Augmented Generation). Requires a POST request with a query message in the body.",
                "request_body": {
                    "query": "string (Your query for chat)"
                },
                "response": {
                    "response": "string (Response generated by GPT model based on Pinecone retrieval)"
                }
            }
        },
        "note": "If you encounter a CORS error, it is due to your endpoint not being allowed. Please contact the server team so that they can add your endpoint to the allowed list."
    }
